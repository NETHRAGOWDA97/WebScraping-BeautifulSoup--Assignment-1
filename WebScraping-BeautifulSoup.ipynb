{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup-WebScraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted by Nethravathi S.  Batch No:1831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nethravathi s\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page1 = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu',\n",
       " 'Personal tools',\n",
       " 'Namespaces',\n",
       " 'Variants',\n",
       " 'Views',\n",
       " 'More',\n",
       " 'Search',\n",
       " 'Navigation',\n",
       " 'Contribute',\n",
       " 'Tools',\n",
       " 'Print/export',\n",
       " 'In other projects',\n",
       " 'Languages']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page content\n",
    "soup=BeautifulSoup(page1.content)\n",
    "\n",
    "soup = BeautifulSoup(page1.text,\"html.parser\")\n",
    "                     \n",
    "Header_tags = [] # empty list\n",
    "for i in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    Header_tags.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "# print all header_tags\n",
    "Header_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send get request to the webpage of the server to get the source code of the page\n",
    "page2 = requests.get(\"https://www.imdb.com/list/ls091520106/\")\n",
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "soup=BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page2.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Shawshank Redemption',\n",
       " 'The Godfather',\n",
       " 'The Godfather: Part II',\n",
       " 'The Dark Knight',\n",
       " '12 Angry Men',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'Pulp Fiction',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " 'Fight Club',\n",
       " 'Joker',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Forrest Gump',\n",
       " 'Inception',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'The Lord of the Rings: The Two Towers',\n",
       " 'The Matrix',\n",
       " \"One Flew Over the Cuckoo's Nest\",\n",
       " 'Goodfellas',\n",
       " 'Shichinin no samurai',\n",
       " 'Se7en',\n",
       " 'Cidade de Deus',\n",
       " 'La vita è bella',\n",
       " 'The Silence of the Lambs',\n",
       " 'Star Wars',\n",
       " \"It's a Wonderful Life\",\n",
       " 'Saving Private Ryan',\n",
       " 'Sen to Chihiro no kamikakushi',\n",
       " 'The Green Mile',\n",
       " 'Léon',\n",
       " 'Seppuku',\n",
       " 'Interstellar',\n",
       " 'The Usual Suspects',\n",
       " 'The Lion King',\n",
       " 'American History X',\n",
       " 'Back to the Future',\n",
       " 'The Pianist',\n",
       " 'Modern Times',\n",
       " 'Terminator 2: Judgment Day',\n",
       " 'The Intouchables',\n",
       " 'Psycho',\n",
       " 'Gladiator',\n",
       " 'City Lights',\n",
       " 'The Departed',\n",
       " 'Whiplash',\n",
       " 'Once Upon a Time in the West',\n",
       " 'The Prestige',\n",
       " 'Avengers: Endgame',\n",
       " 'Casablanca',\n",
       " 'Hotaru no haka',\n",
       " 'Rear Window',\n",
       " 'Nuovo Cinema Paradiso',\n",
       " 'Alien',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Memento',\n",
       " 'Apocalypse Now',\n",
       " 'The Great Dictator',\n",
       " 'The Lives of Others',\n",
       " 'Avengers: Infinity War',\n",
       " 'Django Unchained',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'The Shining',\n",
       " 'Paths of Glory',\n",
       " 'WALL·E',\n",
       " 'Sunset Blvd.',\n",
       " 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb',\n",
       " 'Mononoke-hime',\n",
       " 'Oldeuboi',\n",
       " 'Witness for the Prosecution',\n",
       " 'The Dark Knight Rises',\n",
       " 'Once Upon a Time in America',\n",
       " 'Gisaengchung',\n",
       " 'Aliens',\n",
       " 'American Beauty',\n",
       " 'Coco',\n",
       " 'Kimi no na wa.',\n",
       " 'Braveheart',\n",
       " 'Das Boot',\n",
       " '3 Idiots',\n",
       " 'Taare Zameen Par',\n",
       " 'Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Toy Story',\n",
       " 'Reservoir Dogs',\n",
       " 'Amadeus',\n",
       " 'Dangal',\n",
       " 'Good Will Hunting',\n",
       " 'Inglourious Basterds',\n",
       " 'M - Eine Stadt sucht einen Mörder',\n",
       " 'Requiem for a Dream',\n",
       " '2001: A Space Odyssey',\n",
       " 'Vertigo',\n",
       " 'Eternal Sunshine of the Spotless Mind',\n",
       " 'Citizen Kane',\n",
       " 'Full Metal Jacket',\n",
       " 'Jagten',\n",
       " 'North by Northwest',\n",
       " 'A Clockwork Orange',\n",
       " 'Snatch',\n",
       " \"Le fabuleux destin d'Amélie Poulain\",\n",
       " 'The Kid']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrap movie names\n",
    "name = soup.find_all('h3',class_=\"lister-item-header\")\n",
    "\n",
    "# parse movie names\n",
    "movies_name = []  #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text.replace('\\n',' ').strip())\n",
    "movies_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrap IMDB ratings for movies\n",
    "ratings = soup.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# parse ratings\n",
    "movie_ratings = []  # empty list\n",
    "for i in ratings:\n",
    "    movie_ratings.append(i.text.replace('\\n',' ').strip())\n",
    "movie_ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1994',\n",
       " '1972',\n",
       " '1974',\n",
       " '2008',\n",
       " '1957',\n",
       " '1993',\n",
       " '2003',\n",
       " '1994',\n",
       " '1966',\n",
       " '1999',\n",
       " '2019',\n",
       " '2001',\n",
       " '1994',\n",
       " '2010',\n",
       " '1980',\n",
       " '2002',\n",
       " '1999',\n",
       " '1975',\n",
       " '1990',\n",
       " '1954',\n",
       " '1995',\n",
       " '2002',\n",
       " '1997',\n",
       " '1991',\n",
       " '1977',\n",
       " '1946',\n",
       " '1998',\n",
       " '2001',\n",
       " '1999',\n",
       " '1994',\n",
       " '1962',\n",
       " '2014',\n",
       " '1995',\n",
       " '1994',\n",
       " '1998',\n",
       " '1985',\n",
       " '2002',\n",
       " '1936',\n",
       " '1991',\n",
       " '2011',\n",
       " '1960',\n",
       " '2000',\n",
       " '1931',\n",
       " '2006',\n",
       " '2014',\n",
       " '1968',\n",
       " '2006',\n",
       " '2019',\n",
       " '1942',\n",
       " '1988',\n",
       " '1954',\n",
       " '1988',\n",
       " '1979',\n",
       " '1981',\n",
       " '2000',\n",
       " '1979',\n",
       " '1940',\n",
       " '2006',\n",
       " '2018',\n",
       " '2012',\n",
       " '2018',\n",
       " '1980',\n",
       " '1957',\n",
       " '2008',\n",
       " '1950',\n",
       " '1964',\n",
       " '1997',\n",
       " '2003',\n",
       " '1957',\n",
       " '2012',\n",
       " '1984',\n",
       " '2019',\n",
       " '1986',\n",
       " '1999',\n",
       " 'I 2017',\n",
       " '2016',\n",
       " '1995',\n",
       " '1981',\n",
       " '2009',\n",
       " '2007',\n",
       " '1983',\n",
       " '1995',\n",
       " '1992',\n",
       " '1984',\n",
       " '2016',\n",
       " '1997',\n",
       " '2009',\n",
       " '1931',\n",
       " '2000',\n",
       " '1968',\n",
       " '1958',\n",
       " '2004',\n",
       " '1941',\n",
       " '1987',\n",
       " '2012',\n",
       " '1959',\n",
       " '1971',\n",
       " '2000',\n",
       " '2001',\n",
       " '1921']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# year of release\n",
    "year = soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "\n",
    "Release_year= []  #empty lsit\n",
    "for i in year:\n",
    "        Release_year.append(i.text.replace('(','').replace(')',''))\n",
    "Release_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Release_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(movies_name),len(movie_ratings),len(Release_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Release Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Movies Name Ratings Release Year\n",
       "0              The Shawshank Redemption     9.3         1994\n",
       "1                         The Godfather     9.2         1972\n",
       "2                The Godfather: Part II       9         1974\n",
       "3                       The Dark Knight       9         2008\n",
       "4                          12 Angry Men       9         1957\n",
       "..                                  ...     ...          ...\n",
       "95                   North by Northwest     8.3         1959\n",
       "96                   A Clockwork Orange     8.3         1971\n",
       "97                               Snatch     8.3         2000\n",
       "98  Le fabuleux destin d'Amélie Poulain     8.3         2001\n",
       "99                              The Kid     8.3         1921\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe for top 100 movies in IMDB\n",
    "top_100_movies = pd.DataFrame({})\n",
    "top_100_movies['Movies Name'] = movies_name\n",
    "top_100_movies['Ratings'] = movie_ratings\n",
    "top_100_movies['Release Year'] = Release_year\n",
    "top_100_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_100_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send get request to the webpage of the server to get the source code of the page\n",
    "page3 = requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "page3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the page content\n",
    "soup = BeautifulSoup(page3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page3.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nayakan',\n",
       " 'Pariyerum Perumal',\n",
       " 'Anbe Sivam',\n",
       " 'C/o Kancharapalem',\n",
       " 'Golmaal',\n",
       " 'Pather Panchali',\n",
       " 'Apur Sansar',\n",
       " 'Manichitrathazhu',\n",
       " 'Kireedam',\n",
       " 'Natsamrat',\n",
       " '96',\n",
       " 'Thevar Magan',\n",
       " 'Black Friday',\n",
       " 'Kumbalangi Nights',\n",
       " 'Visaaranai',\n",
       " '3 Idiots',\n",
       " 'Drishyam 2',\n",
       " 'Soorarai Pottru',\n",
       " 'Jersey',\n",
       " 'Taare Zameen Par',\n",
       " 'Thalapathi',\n",
       " 'Asuran',\n",
       " 'Dangal',\n",
       " 'Kaithi',\n",
       " 'Ratsasan',\n",
       " 'Devasuram',\n",
       " 'Aparajito',\n",
       " 'Jaane Bhi Do Yaaro',\n",
       " 'Sarpatta Parambarai',\n",
       " 'Pyaasa',\n",
       " 'Vada Chennai',\n",
       " 'Peranbu',\n",
       " 'Guide',\n",
       " 'Thani Oruvan',\n",
       " 'Kannathil Muthamittal',\n",
       " 'Iruvar',\n",
       " 'Chupke Chupke',\n",
       " 'Spadikam',\n",
       " 'Agent Sai Srinivasa Athreya',\n",
       " 'Super Deluxe',\n",
       " 'Drishyam',\n",
       " 'Mahanati',\n",
       " 'Aruvi',\n",
       " 'Vikram Vedha',\n",
       " 'Khosla Ka Ghosla!',\n",
       " 'Tumbbad',\n",
       " 'Pudhu Pettai',\n",
       " 'Premam',\n",
       " 'Anniyan',\n",
       " 'Anand',\n",
       " 'Kaakkaa Muttai',\n",
       " 'Mudhalvan',\n",
       " 'Bangalore Days',\n",
       " 'Dhuruvangal Pathinaaru',\n",
       " 'Papanasam',\n",
       " 'Satya',\n",
       " 'Andhadhun',\n",
       " 'Soodhu Kavvum',\n",
       " 'Shahid',\n",
       " 'Jigarthanda',\n",
       " 'Gangs of Wasseypur',\n",
       " 'Pithamagan',\n",
       " 'Paan Singh Tomar',\n",
       " 'Bhaag Milkha Bhaag',\n",
       " 'Hera Pheri',\n",
       " 'Sairat',\n",
       " 'Talvar',\n",
       " 'Sholay',\n",
       " 'Swades: We, the People',\n",
       " 'Chak De! India',\n",
       " 'Ustad Hotel',\n",
       " 'Black',\n",
       " 'Drishyam',\n",
       " 'Jo Jeeta Wohi Sikandar',\n",
       " 'Zindagi Na Milegi Dobara',\n",
       " 'Mughal-E-Azam',\n",
       " 'Maheshinte Prathikaaram',\n",
       " 'Nil Battey Sannata',\n",
       " 'Udaan',\n",
       " 'Charulata',\n",
       " 'Theeran adhigaaram ondru',\n",
       " 'Article 15',\n",
       " 'A Wednesday',\n",
       " 'Queen',\n",
       " 'Masaan',\n",
       " 'Munna Bhai M.B.B.S.',\n",
       " 'Alai Payuthey',\n",
       " 'Sarfarosh',\n",
       " 'Baasha',\n",
       " 'Dil Chahta Hai',\n",
       " 'OMG: Oh My God!',\n",
       " 'Chhichhore',\n",
       " 'Roja',\n",
       " 'Rang De Basanti',\n",
       " 'Virumandi',\n",
       " 'Andaz Apna Apna',\n",
       " 'Lagaan: Once Upon a Time in India',\n",
       " 'Kahaani',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'PK']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrap top 100 Indian movie names\n",
    "name = soup.find_all('td',class_=\"titleColumn\")\n",
    "\n",
    "# parse movie names\n",
    "Indian_movies_name = []  #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Indian_movies_name.append(j.text.replace('\\n',' '))\n",
    "Indian_movies_name = Indian_movies_name[:100]\n",
    "Indian_movies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Indian_movies_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrap IMDB ratings for Indian movies\n",
    "ratings = soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "# parse ratings\n",
    "movie_ratings = []\n",
    "for i in ratings:\n",
    "    movie_ratings.append(i.text.replace('\\n',' ').strip())\n",
    "movie_ratings = movie_ratings[:100]\n",
    "movie_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1987',\n",
       " '2018',\n",
       " '2003',\n",
       " '2018',\n",
       " '1979',\n",
       " '1955',\n",
       " '1959',\n",
       " '1993',\n",
       " '1989',\n",
       " '2016',\n",
       " '2018',\n",
       " '1992',\n",
       " '2004',\n",
       " '2019',\n",
       " '2015',\n",
       " '2009',\n",
       " '2021',\n",
       " '2020',\n",
       " '2019',\n",
       " '2007',\n",
       " '1991',\n",
       " '2019',\n",
       " '2016',\n",
       " '2019',\n",
       " '2018',\n",
       " '1993',\n",
       " '1956',\n",
       " '1983',\n",
       " '2021',\n",
       " '1957',\n",
       " '2018',\n",
       " '2018',\n",
       " '1965',\n",
       " '2015',\n",
       " '2002',\n",
       " '1997',\n",
       " '1975',\n",
       " '1995',\n",
       " '2019',\n",
       " '2019',\n",
       " '2013',\n",
       " '2018',\n",
       " '2016',\n",
       " '2017',\n",
       " '2006',\n",
       " '2018',\n",
       " '2006',\n",
       " '2015',\n",
       " '2005',\n",
       " '1971',\n",
       " '2014',\n",
       " '1999',\n",
       " '2014',\n",
       " '2016',\n",
       " '2015',\n",
       " '1998',\n",
       " '2018',\n",
       " '2013',\n",
       " '2012',\n",
       " '2014',\n",
       " '2012',\n",
       " '2003',\n",
       " '2012',\n",
       " '2013',\n",
       " '2000',\n",
       " '2016',\n",
       " '2015',\n",
       " '1975',\n",
       " '2004',\n",
       " '2007',\n",
       " '2012',\n",
       " '2005',\n",
       " '2015',\n",
       " '1992',\n",
       " '2011',\n",
       " '1960',\n",
       " '2016',\n",
       " '2015',\n",
       " '2010',\n",
       " '1964',\n",
       " '2017',\n",
       " '2019',\n",
       " '2008',\n",
       " '2013',\n",
       " '2015',\n",
       " '2003',\n",
       " '2000',\n",
       " '1999',\n",
       " '1995',\n",
       " '2001',\n",
       " '2012',\n",
       " '2019',\n",
       " '1992',\n",
       " '2006',\n",
       " '2004',\n",
       " '1994',\n",
       " '2001',\n",
       " '2012',\n",
       " '2018',\n",
       " '2014']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrap the year of release\n",
    "year_of_release = soup.find_all(\"span\",class_=\"secondaryInfo\")\n",
    "\n",
    "#parse release year\n",
    "Release_year= []  #empty lsit\n",
    "for i in name:\n",
    "    for j in i.find_all(\"span\"):\n",
    "        Release_year.append(j.text.replace('(','').replace(')',''))\n",
    "Release_year = Release_year[:100]\n",
    "Release_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Release_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Indian_movies_name),len(movie_ratings),len(Release_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Andaz Apna Apna</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PK</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Movies Name Ratings Year of Release\n",
       "0                             Nayakan     8.5            1987\n",
       "1                   Pariyerum Perumal     8.5            2018\n",
       "2                          Anbe Sivam     8.5            2003\n",
       "3                   C/o Kancharapalem     8.5            2018\n",
       "4                             Golmaal     8.5            1979\n",
       "..                                ...     ...             ...\n",
       "95                    Andaz Apna Apna     8.1            1994\n",
       "96  Lagaan: Once Upon a Time in India     8.1            2001\n",
       "97                            Kahaani     8.1            2012\n",
       "98           Uri: The Surgical Strike     8.1            2018\n",
       "99                                 PK     8.1            2014\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe for top 100  Indiam movies in IMDB\n",
    "top_100_movies = pd.DataFrame({})\n",
    "top_100_movies['Movies Name'] = Indian_movies_name\n",
    "top_100_movies['Ratings'] = movie_ratings\n",
    "top_100_movies['Year of Release'] = Release_year\n",
    "top_100_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_100_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Write a python program to scrap book name, author name, genre and book review of any 5 books from‘www.bookpage.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page4 = requests.get(\"https://bookpage.com/reviews/\")\n",
    "page4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page content\n",
    "soup = BeautifulSoup(page4.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4 class=\"italic\">\n",
       " <a href=\"/reviews/26469-derek-b-miller-how-to-find-your-way-dark-fiction\"> <span style=\"font-style:normal;\">★ </span>How to Find Your Way in the Dark</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26544-k-b-wagers-hold-fast-through-fire-science-fiction-fantasy\">Hold Fast Through the Fire</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26542-darynda-jones-good-day-chardonnay-mystery-suspense\">A Good Day for Chardonnay</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26466-mona-awad-alls-well-fiction\">All’s Well</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26490-rodrigo-garcia-farewell-to-gabo-mercedes-nonfiction\"> <span style=\"font-style:normal;\">★ </span>A Farewell to Gabo and Mercedes</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26474-jeanne-thornton-summer-fun-fiction\"> <span style=\"font-style:normal;\">★ </span>Summer Fun</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26536-malla-nunn-sugar-town-queens-ya\"> <span style=\"font-style:normal;\">★ </span>Sugar Town Queens</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26462-natalie-baszile-we-are-each-others-harvest-audio\">We Are Each Other’s Harvest</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26485-jerry-spinelli-dead-wednesday-childrens\"> <span style=\"font-style:normal;\">★ </span>Dead Wednesday</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26461-casey-wilson-wreckage-my-presence-audio\">The Wreckage of My Presence</a>\n",
       " </h4>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract books URL\n",
    "url_tags = soup.find_all(\"h4\",class_=\"italic\")\n",
    "url_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/reviews/26469-derek-b-miller-how-to-find-your-way-dark-fiction',\n",
       " '/reviews/26544-k-b-wagers-hold-fast-through-fire-science-fiction-fantasy',\n",
       " '/reviews/26542-darynda-jones-good-day-chardonnay-mystery-suspense',\n",
       " '/reviews/26466-mona-awad-alls-well-fiction',\n",
       " '/reviews/26490-rodrigo-garcia-farewell-to-gabo-mercedes-nonfiction',\n",
       " '/reviews/26474-jeanne-thornton-summer-fun-fiction',\n",
       " '/reviews/26536-malla-nunn-sugar-town-queens-ya',\n",
       " '/reviews/26462-natalie-baszile-we-are-each-others-harvest-audio',\n",
       " '/reviews/26485-jerry-spinelli-dead-wednesday-childrens',\n",
       " '/reviews/26461-casey-wilson-wreckage-my-presence-audio']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the links\n",
    "urls = []\n",
    "for i in url_tags:\n",
    "    for j in i.find_all(\"a\", href=True):\n",
    "        if j.text:\n",
    "            urls.append(j['href'])\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = [] #empty list\n",
    "author_name = [] #empty list\n",
    "book_genre = [] #empty list\n",
    "books_review = [] #empty list\n",
    "\n",
    "for url in urls:\n",
    "        book = requests.get('https://www.bookpage.com'+url)\n",
    "        soup = BeautifulSoup(book.content, 'html.parser')\n",
    "        book_name.append(soup.find('h1').text.replace('\\n','').replace('★',''))  # scrape books name\n",
    "        author_name.append(soup.find('h4').text.replace('\\n',''))  # scrape books author name\n",
    "        book_genre.append(soup.find('p', class_=\"genre-links\").text.replace('\\n',''))   # scrape books genre\n",
    "        books_review.append(soup.find('div', class_= \"article-body\").text.replace('\\n',''))  # scrape books review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' How to Find Your Way in the Dark',\n",
       " 'Hold Fast Through the Fire',\n",
       " 'A Good Day for Chardonnay',\n",
       " 'All’s Well',\n",
       " ' A Farewell to Gabo and Mercedes']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name = book_name[:5]\n",
    "book_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Derek B. Miller',\n",
       " 'K.B. Wagers',\n",
       " 'Darynda Jones',\n",
       " 'Mona Awad',\n",
       " 'Rodrigo García']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name = author_name[:5]\n",
    "author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fiction / Coming of Age',\n",
       " 'Science Fiction & Fantasy / Science Fiction',\n",
       " 'Mystery & Suspense / Mystery',\n",
       " 'Fiction / Literary Fiction',\n",
       " 'Nonfiction / Memoir / Family & Relationships']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_genre = book_genre[:5]\n",
    "book_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Prepare for surprises galore in How to Find Your Way in the Dark, a rollicking novel that begins with a lonely truck ride in New England in 1938 and follows its characters through a decade of fascinating history. Just when you think the story is heading one way, it veers in another, completely unexpected direction.Twelve-year-old Sheldon Horowitz and his father are driving home from Hartford, Connecticut, to Whately, Massachusetts, after honoring the one-year anniversary of Sheldon’s mother’s death. She and her sister died in a horrific movie theater fire in Hartford. And as if that isn’t enough tragedy for the novel’s first 13 pages, a truck purposely forces Sheldon and his father’s car off the road during their return trip, and Sheldon’s father dies.Readers of Derek B. Miller’s award-winning thriller, Norwegian by Night, will recognize Sheldon as that novel’s 82-year-old protagonist. As a Tom Sawyer-like boy in How to Find Your Way in the Dark, Sheldon is determined to make sense of his double tragedies, and his attempts to do so take the reader on one hell of a ride. As he seeks out the leering, mustached truck driver who killed his father, his quest leads him straight into danger—think mobsters, guns and jewel thefts.Miller has crafted a wide-ranging, years-spanning yet tightly structured plot, and he excels at placing memorable characters in unusual circumstances. Sheldon is joined in his adventures by his two older cousins, Abe and Mirabelle, and his best friend, Lenny, all of whom play pivotal roles. One summer, Lenny and Sheldon end up as bellhops at the famed Grossinger’s Resort in the Catskills, where Lenny practices standup comedy amid the glamorous, bustling atmosphere.An underlying seriousness lies at the heart of all of this intrigue, hilarity and fun. Sheldon, Abe, Mirabelle and Lenny, all Jewish, must confront the many faces of antisemitism during the turbulent years of World War II. Miller weaves in a multitude of historical details, including reports of the horrors in Europe and America’s reluctance to intervene.The ending of How to Find Your Way in the Dark is nothing short of brilliant, tying up a variety of loose ends while making a powerful statement about the need to fully recognize and address antisemitism. Readers are left with much to ponder, including life’s many uncertainties and cruel twists of fate. Despite these unhappy truths, we are also left with the uplifting wisdom of Lenny’s urgent prayer: “Dear God, give me the strength to be joyful.”',\n",
       " 'Looking for a quick bit of adrenaline, a spot of intrigue and the drama of an international sports event? Look no further than the second entry in K.B. Wagers’ NeoG series, Hold Fast Through the Fire.This second book in the author’s military science fiction series picks up roughly a year after the events of A Pale Light in the Black. The crew of Zuma’s Ghost have achieved a repeat victory at the intermilitary Boarding Games, which was quite an achievement given that the Near-Earth Orbital Guard (NeoG) are looked down upon by other branches of the armed forces. Zuma’s Ghost is facing a change of staff, and everyone is uneasy about what that means for the future of the ship. The prelims for the next year’s Games are fast approaching, and the Ghost has been put on a new task force to investigate potential smuggling issues from off-world settlements.Nika, still off balance from the loss of his hand, is apprehensive about his new command on Zuma’s Ghost, despite the fact that it was the ship where he cut his teeth as a budding lieutenant. His budding romance with Maxine Carmichael is on the rocks, and to make things worse, he has accepted a secret assignment that will put both Max’s and the crew’s trust to the test. Chae, Zuma’s Ghost’s new pilot, has issues of their own. Forced into the NeoG as part of a plea bargain, they are torn between their growing loyalty to their new crew and the need to keep their fathers safe from intergalactic intrigue. Meanwhile, Max is certain something is desperately wrong with Nika, Chae and their new assignment, but no one will back her up. With Nika effectively gaslighting her to throw her off the scent of his new top-secret mission, Max will have to hew closely to her own instincts if she is going to get the team through the prelims in one piece—let alone their official assignment.Unlike A Pale Light in the Black, Hold Fast Through the Fire’s central mystery begins unrolling nearly at page one, giving the book a more sinister feel than its predecessor and pulling readers into a labyrinthine plot that surprises and delights. This does take away slightly from the Games aspect of the series, but readers who enjoyed A Pale Light in the Black’s focus on the competition won’t be disappointed. When training for the Games does make its appearance, it still packs the same adrenaline-filled punch of A Pale Light in the Black. Despite the increase in intrigue, Wagers devotes ample attention to the relationships among the crew of Zuma’s Ghost. From the exploration of Jenks’ and Max’s close friendship to Chae’s struggles to fit in with the group to Nika’s battle to accept himself after his accident, Hold Fast Through the Fire is as much about found family and interpersonal relationships as it is about mysteries or the Boarding Games.This brilliant and entertaining installment in the NeoG universe is a great choice for readers looking for military drama, evocative writing and espionage.',\n",
       " 'Readers who enjoy murder mysteries\\xa0with lots of intertwined plotlines, quirky characters and zany hijinks topped off with a healthy dose of horniness will be delighted by bestselling author Darynda Jones’ A Good Day for Chardonnay.The small tourist town of Del Sol, New Mexico, is populated by unruly residents who are staunchly community-minded and happen to be, per Sheriff Sunshine Vicram’s hilariously lusty inner monologues, quite desirable. To wit, her chief deputy and BFF Quincy is “sexy feet, AF inches” tall. And her lifelong crush, local-badboy-turned-wealthy-distillery-owner Levi Ravinder? Well, he and his crime-aficionado family look “as though [they were] chiseled by the gods . . . [with] lean, solid bodies and razor-sharp jawlines.”But while Sunshine is often mightily distracted by eye candy, she’s also dedicated to—and excellent at—her job. She’s been back in town for four months after being away for 15 years, and she has multiple mysteries to solve. The newest include a bar fight gone terribly wrong; resurfaced cold cases with ties to her own traumatic past; and a raft of false confessions. On top of that, the mayor is pressuring her to figure out if the Dangerous Daughters secret society (rumored to have run the town for decades) is real or just local legend.And then there’s Sunshine’s daughter Auri, whom fans met in series kickoff A Bad Day for Sunshine. The smart, reckless teenager is determined to solve crimes just like her mom, and she pursues a sweet old lady who might be a serial killer. Auri is also Sunshine’s personal mystery: at 17, the sheriff was abducted by Levi’s uncle and held captive for five days, after which she emerged pregnant and with severe memory loss.Will Levi’s family finally answer Sunshine’s questions about her abduction? Can she catch the marauding raccoon that’s terrorizing the town? How are the cold cases tied to these complex new crimes? With her trademark warmth and humor, Jones answers some of these questions and raises even more, nicely teeing up the next installment in Sunshine’s complicated, sexy and highly entertaining life story.',\n",
       " 'Miranda Fitch, the protagonist of Mona Awad’s third novel, All’s Well, might best be described—to borrow the title of the 1988 Pedro Almodóvar film—as a woman on the verge of a nervous breakdown. A professor of theater studies at a small liberal arts college in Massachusetts, she’s laboring mightily to stage a student production of Shakespeare’s All’s Well That Ends Well, which she thinks of as a “problem play,” one that’s “neither a tragedy nor a comedy. Both, always both.”Apart from a rebellious cast, Miranda’s primary obstacle is unremitting pain from an injury she sustained when she tumbled from a stage during her promising but brief acting career. The resulting hip injury led to serious back problems unrelieved by the ministrations of a string of doctors and physical therapists, transforming Miranda, divorced and not yet 40 years old, into a pill-gobbling automaton who has abandoned all hope of her own happy ending.All’s Well quickly leaves behind this depressingly naturalistic scenario to veer into the realm of fabulism when Miranda encounters three mysterious men in a local pub. The trio, who inexplicably have intimate knowledge of her life and struggles, grace her with what seems like a miracle cure. But as she discovers, even healing can come at a price.Awad efficiently portrays both Miranda’s confrontation with chronic pain and the slowly evaporating patience of the people in her orbit (her ex-husband, Paul; colleague and friend Grace; and Mark, the last in a chain of physical therapists) with her lack of improvement. Anyone who’s been similarly afflicted or knows someone who has will recognize this scenario. Awad leaves it to the reader to assess how much of Miranda’s mental turmoil is the product of an inexplicable but desperately welcome truce in her battle with pain, and how much flows from her encounter with supernatural forces. It’s a wild, at times over-the-top ride, but like Shakespeare’s eponymous work, there’s both pathos and humor in this story of how we suffer and the ways in which we’re healed.',\n",
       " \"Rodrigo García is a film and television director, writer, cinematographer and son of the late Nobel winner Gabriel García Márquez, affectionately known as Gabo, author of One Hundred Years of Solitude and Love in the Time of Cholera. When García’s world-famous father began his long slide toward dementia, García began taking notes. “Writing about the death of loved ones must be about as old as writing itself, and yet the inclination to do it instantly ties me up in knots,” he writes. “I am appalled that I am thinking of taking notes, ashamed as I take notes, disappointed in myself as I revise notes.”All who have loved García Márquez’s works will rejoice that his son overcame that angst, dutifully waiting until after his father’s death in 2014 and his mother’s death in 2020 to publish his intimate, endearing tribute, A Farewell to Gabo and Mercedes: A Son’s Memoir of Gabriel García Márquez and Mercedes Barcha. García’s notes, acutely observational, are simultaneously infused with love, respect and the pain of loss. He admits that his relationships with his parents were complicated. Their lives had public, private and even secret components, and García frets about crossing lines that might leave his parents helplessly exposed. Still, from his dying father’s bedside in Mexico City to his last moment with his mother (shared digitally, as COVID-19 prevented him from traveling), García is a guardian of their dignity.\\xa0Yet this memoir’s details are indeed intimate. We're ushered into García Márquez's study as he works, until the renowned author slowly realizes he no longer can. García’s mother rises above her grief, insisting that she is a woman, not a widow, as she entertains the flow of mourning guests from around the globe—even the complete stranger who manages to con her out of quite a bit of cash. We follow García into the crematorium as he gazes upon his father for the last time, tempering that blow with the thought that García Márquez might have enjoyed flirting with the funeral worker who gave his body a little makeup, a final flourish on his way out.Fittingly, García begins each chapter with an excerpt from one of his father’s works, and it’s this connection between life and art that holds this intense memoir together. As one epigraph from Love in the Time of Cholera puts it, “he was overwhelmed by the belated suspicion that it is life, more than death, that has no limits.”\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_review = books_review[:5]\n",
    "books_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5 5\n"
     ]
    }
   ],
   "source": [
    "print(len(book_name),len(author_name),len(book_genre),len(books_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Find Your Way in the Dark</td>\n",
       "      <td>Derek B. Miller</td>\n",
       "      <td>Fiction / Coming of Age</td>\n",
       "      <td>Prepare for surprises galore in How to Find Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hold Fast Through the Fire</td>\n",
       "      <td>K.B. Wagers</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Science Fiction</td>\n",
       "      <td>Looking for a quick bit of adrenaline, a spot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Good Day for Chardonnay</td>\n",
       "      <td>Darynda Jones</td>\n",
       "      <td>Mystery &amp; Suspense / Mystery</td>\n",
       "      <td>Readers who enjoy murder mysteries with lots o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All’s Well</td>\n",
       "      <td>Mona Awad</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>Miranda Fitch, the protagonist of Mona Awad’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Farewell to Gabo and Mercedes</td>\n",
       "      <td>Rodrigo García</td>\n",
       "      <td>Nonfiction / Memoir / Family &amp; Relationships</td>\n",
       "      <td>Rodrigo García is a film and television direct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Book Name           Author  \\\n",
       "0   How to Find Your Way in the Dark  Derek B. Miller   \n",
       "1         Hold Fast Through the Fire      K.B. Wagers   \n",
       "2          A Good Day for Chardonnay    Darynda Jones   \n",
       "3                         All’s Well        Mona Awad   \n",
       "4    A Farewell to Gabo and Mercedes   Rodrigo García   \n",
       "\n",
       "                                          Genre  \\\n",
       "0                       Fiction / Coming of Age   \n",
       "1   Science Fiction & Fantasy / Science Fiction   \n",
       "2                  Mystery & Suspense / Mystery   \n",
       "3                    Fiction / Literary Fiction   \n",
       "4  Nonfiction / Memoir / Family & Relationships   \n",
       "\n",
       "                                              Review  \n",
       "0  Prepare for surprises galore in How to Find Yo...  \n",
       "1  Looking for a quick bit of adrenaline, a spot ...  \n",
       "2  Readers who enjoy murder mysteries with lots o...  \n",
       "3  Miranda Fitch, the protagonist of Mona Awad’s ...  \n",
       "4  Rodrigo García is a film and television direct...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame \n",
    "books=pd.DataFrame({})\n",
    "books[\"Book Name\"]=book_name\n",
    "books[\"Author\"]=author_name\n",
    "books[\"Genre\"]=book_genre\n",
    "books[\"Review\"]=books_review\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send get request to the webpage of the server to get the source code of the page\n",
    "page5 = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "page5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see content in page\n",
    "soup = BeautifulSoup(page5.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page5.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'West Indies',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape team names\n",
    "name = soup.find_all(\"span\",class_=\"u-hide-phablet\")\n",
    "\n",
    "teams_name = []\n",
    "for i in name:\n",
    "    teams_name.append(i.text.replace('\\n',''))\n",
    "teams_name = teams_name[:10]\n",
    "teams_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teams_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape matches\n",
    "match1 = soup.find_all(\"td\",class_=\"rankings-block__banner--matches\")   #first place team number of matches\n",
    "\n",
    "no_of_matches = [] #empty list\n",
    "for i in match1:\n",
    "    no_of_matches.append(i.text)\n",
    "no_of_matches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '32', '27', '32', '22', '27', '29', '29', '29', '17']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = []  #emptty list\n",
    "matches = soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")   #other teams number of matches\n",
    "\n",
    "for i in matches:\n",
    "    new_list.append(i.text)\n",
    "new_list  \n",
    "\n",
    "for i in range(0,len( new_list),2):\n",
    "    no_of_matches.append(new_list[i])\n",
    "no_of_matches = no_of_matches[:10]\n",
    "no_of_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_of_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054',\n",
       " '3,793',\n",
       " '3,109',\n",
       " '3,624',\n",
       " '2,267',\n",
       " '2,524',\n",
       " '2,639',\n",
       " '2,458',\n",
       " '2,303',\n",
       " '1,054']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape points\n",
    "pts_1 = soup.find_all(\"td\",class_=\"rankings-block__banner--points\")   #first place team points\n",
    "\n",
    "points = [] #empty list\n",
    "for i in pts_1:\n",
    "    points.append(i.text)\n",
    "\n",
    "new_list = []  #emptty list\n",
    "pts = soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")   #other teams points\n",
    "\n",
    "for i in pts:\n",
    "    new_list.append(i.text)\n",
    "new_list  \n",
    "\n",
    "for i in range(0,len( new_list),2):\n",
    "    points.append(new_list[i+1])\n",
    "points = points[:10]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['121', '119', '115', '113', '103', '93', '91', '85', '79', '62']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape ratings\n",
    "rtgs_1 = soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\")   #first place team ratings\n",
    "\n",
    "ratings = [] #empty list\n",
    "for i in rtgs_1:\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "\n",
    "rtgs = soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\")   #other teams ratings\n",
    "    \n",
    "for i in rtgs:\n",
    "    ratings.append(i.text)\n",
    "ratings= ratings[:10]\n",
    "ratings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(teams_name),len(no_of_matches),len(points),len(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>27</td>\n",
       "      <td>3,109</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>22</td>\n",
       "      <td>2,267</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>29</td>\n",
       "      <td>2,639</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,458</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,303</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points Ratings\n",
       "0   New Zealand      17  2,054     121\n",
       "1       England      32  3,793     119\n",
       "2     Australia      27  3,109     115\n",
       "3         India      32  3,624     113\n",
       "4  South Africa      22  2,267     103\n",
       "5      Pakistan      27  2,524      93\n",
       "6    Bangladesh      29  2,639      91\n",
       "7   West Indies      29  2,458      85\n",
       "8     Sri Lanka      29  2,303      79\n",
       "9   Afghanistan      17  1,054      62"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dataframe of top 10 men's ODI teams\n",
    "men_odi=pd.DataFrame({})\n",
    "men_odi['Team_name']=teams_name\n",
    "men_odi['Matches']=no_of_matches\n",
    "men_odi['Points']=points\n",
    "men_odi['Ratings']=ratings\n",
    "men_odi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(men_odi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page6 = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "page6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page6\n",
    "soup = BeautifulSoup(page6.content)\n",
    "soup =  BeautifulSoup(page6.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_name = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Ross Taylor',\n",
       " 'Aaron Finch',\n",
       " 'Jonny Bairstow',\n",
       " 'David Warner',\n",
       " 'Shai Hope',\n",
       " 'Francois du Plessis',\n",
       " 'Quinton de Kock']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape players\n",
    "player_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\")  #first place player name\n",
    "\n",
    "players_name = [] #empty list\n",
    "for i in player_1:\n",
    "    players_name.append(i.text)\n",
    "\n",
    "other_players = soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")  # other players\n",
    "\n",
    "for i in other_players:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        players_name.append(j.text)\n",
    "players_name = players_name[:10]\n",
    "players_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(players_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'IND', 'IND', 'NZ', 'AUS', 'ENG', 'AUS', 'WI', 'SA', 'SA']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape team name\n",
    "team_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\")   #first place team name\n",
    "\n",
    "team_name = []  #empty list\n",
    "for i in team_1:\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "other_teams = soup.find_all(\"span\",class_=\"table-body__logo-text\")  # other teams name\n",
    "\n",
    "for i in other_teams:\n",
    "    team_name.append(i.text)\n",
    "team_name = team_name[:10]\n",
    "team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['873', '848', '817', '801', '791', '775', '773', '773', '766', '758']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape ratings\n",
    "rating_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--rating\")    #first place player ratings\n",
    "\n",
    "rating = []  #empty list\n",
    "for i in rating_1:\n",
    "    rating.append(i.text)\n",
    "\n",
    "others_ratings = soup.find_all(\"td\",class_=\"table-body__cell rating\")      #other players ratings\n",
    "\n",
    "for i in others_ratings:\n",
    "    rating.append(i.text)\n",
    "rating = rating[:10]\n",
    "rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(players_name),len(team_name),len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0           Babar Azam  PAK    873\n",
       "1          Virat Kohli  IND    848\n",
       "2         Rohit Sharma  IND    817\n",
       "3          Ross Taylor   NZ    801\n",
       "4          Aaron Finch  AUS    791\n",
       "5       Jonny Bairstow  ENG    775\n",
       "6         David Warner  AUS    773\n",
       "7            Shai Hope   WI    773\n",
       "8  Francois du Plessis   SA    766\n",
       "9      Quinton de Kock   SA    758"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of top 10 ODI Batsmen\n",
    "ODI_Batsmen=pd.DataFrame({})\n",
    "ODI_Batsmen['Player']=players_name\n",
    "ODI_Batsmen['Team']=team_name\n",
    "ODI_Batsmen['Rating']=rating\n",
    "ODI_Batsmen[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ODI_Batsmen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page7 = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "page7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page7.content)\n",
    "soup =  BeautifulSoup(page7.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlers_name = []   #empty list\n",
    "team_name = []   #empty list\n",
    "ratings = []   #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Chris Woakes',\n",
       " 'Mehedi Hasan',\n",
       " 'Matt Henry',\n",
       " 'Jasprit Bumrah',\n",
       " 'Josh Hazlewood',\n",
       " 'Shakib Al Hasan',\n",
       " 'Kagiso Rabada',\n",
       " 'Pat Cummins']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape bowlers name\n",
    "bowler_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\")   #first place bowler name\n",
    "\n",
    "bowlers_name = []   #empty list\n",
    "for i in bowler_1:\n",
    "    bowlers_name.append(i.text)\n",
    "\n",
    "other_bowlers = soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")   #other bowlers name\n",
    "\n",
    "for i in other_bowlers:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        bowlers_name.append(j.text)\n",
    "bowlers_name = bowlers_name[:10]\n",
    "bowlers_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bowlers_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NZ', 'AFG', 'ENG', 'BAN', 'NZ', 'IND', 'AUS', 'BAN', 'SA', 'AUS']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape team name\n",
    "team_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\")  # first place bowler team name\n",
    "\n",
    "team_name = []   #empty list\n",
    "for i in team_1:\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "other_teams = soup.find_all(\"span\",class_=\"table-body__logo-text\")   # other bowlers team name\n",
    "\n",
    "for i in other_teams:\n",
    "    team_name.append(i.text)\n",
    "team_name = team_name[:10]\n",
    "team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['737', '708', '700', '692', '691', '683', '660', '650', '648', '646']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape ratings\n",
    "rating_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--rating\")   # first place bowler ratings\n",
    "\n",
    "ratings = []   #empty list\n",
    "for i in rating_1:\n",
    "    ratings.append(i.text)\n",
    "ratings\n",
    "\n",
    "others_ratings = soup.find_all(\"td\",class_=\"table-body__cell rating\")   # other bowlers ratings\n",
    "\n",
    "for i in others_ratings:\n",
    "    ratings.append(i.text)\n",
    "ratings = ratings[:10]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(bowlers_name),len(team_name),len(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bowler Team Rating\n",
       "0       Trent Boult   NZ    737\n",
       "1  Mujeeb Ur Rahman  AFG    708\n",
       "2      Chris Woakes  ENG    700\n",
       "3      Mehedi Hasan  BAN    692\n",
       "4        Matt Henry   NZ    691\n",
       "5    Jasprit Bumrah  IND    683\n",
       "6    Josh Hazlewood  AUS    660\n",
       "7   Shakib Al Hasan  BAN    650\n",
       "8     Kagiso Rabada   SA    648\n",
       "9       Pat Cummins  AUS    646"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of top 10 ODI bowlers\n",
    "odi_bowlers=pd.DataFrame({})\n",
    "odi_bowlers['Bowler']=bowlers_name\n",
    "odi_bowlers['Team']=team_name\n",
    "odi_bowlers['Rating']=ratings\n",
    "odi_bowlers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(odi_bowlers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page8 = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "page8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page8.content)\n",
    "soup =  BeautifulSoup(page8.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'Ireland']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape team names\n",
    "women_team = soup.find_all(\"span\",class_=\"u-hide-phablet\")\n",
    "\n",
    "women_team_name = []\n",
    "for i in women_team:\n",
    "    women_team_name.append(i.text.replace('\\n',''))\n",
    "women_team_name = women_team_name[:10]\n",
    "women_team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_matches = [] #empty list\n",
    "women_points = [] #empty list\n",
    "women_ratings = [] #empty list\n",
    "women_new_list = [] #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18', '20', '24', '23', '21', '17', '20', '5', '11', '2']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape matches\n",
    "match_1 = soup.find_all(\"td\",class_=\"rankings-block__banner--matches\")   # first place team number of matches\n",
    "\n",
    "women_matches = [] #empty list\n",
    "for i in match_1:\n",
    "    women_matches.append(i.text)\n",
    "\n",
    "other_matches = soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")  # other teams matches\n",
    "\n",
    "women_new_list = []  #empty list\n",
    "for i in other_matches:\n",
    "    women_new_list.append(i.text)\n",
    "\n",
    "for i in range(0,len(women_new_list),2):\n",
    "    women_matches.append(women_new_list[i])\n",
    "women_matches = women_matches[:10]\n",
    "women_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,955',\n",
       " '2,370',\n",
       " '2,828',\n",
       " '2,535',\n",
       " '1,947',\n",
       " '1,427',\n",
       " '1,496',\n",
       " '306',\n",
       " '519',\n",
       " '25']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape women points\n",
    "point_1 = soup.find_all(\"td\",class_=\"rankings-block__banner--points\")  # first place team points\n",
    "\n",
    "women_points = [] #empty list\n",
    "for i in point_1:\n",
    "    women_points.append(i.text)\n",
    "\n",
    "women_new_list = []  #emptty list\n",
    "others_points = soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")  # other team points\n",
    "\n",
    "for i in others_points:\n",
    "    women_new_list.append(i.text)  \n",
    "\n",
    "for i in range(0,len(women_new_list),2):\n",
    "    women_points.append(women_new_list[i+1])\n",
    "women_points = women_points[:10]\n",
    "women_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['164', '119', '118', '110', '93', '84', '75', '61', '47', '13']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape ratings\n",
    "ratings_1 = soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\")   #first place team ratings\n",
    "\n",
    "women_ratings = [] #empty list\n",
    "for i in ratings_1:\n",
    "    women_ratings.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "others_ratings = soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\")   #other teams ratings\n",
    "    \n",
    "for i in others_ratings:\n",
    "    women_ratings.append(i.text)\n",
    "women_ratings= women_ratings[:10]\n",
    "women_ratings   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(women_matches),len(women_points),len(women_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>20</td>\n",
       "      <td>2,370</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>23</td>\n",
       "      <td>2,535</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>17</td>\n",
       "      <td>1,427</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,496</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points Ratings\n",
       "0     Australia      18  2,955     164\n",
       "1       England      20  2,370     119\n",
       "2  South Africa      24  2,828     118\n",
       "3         India      23  2,535     110\n",
       "4   New Zealand      21  1,947      93\n",
       "5   West Indies      17  1,427      84\n",
       "6      Pakistan      20  1,496      75\n",
       "7    Bangladesh       5    306      61\n",
       "8     Sri Lanka      11    519      47\n",
       "9       Ireland       2     25      13"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of top 10 women ODI teams\n",
    "women_odi=pd.DataFrame({})\n",
    "women_odi['Team_name']=women_team_name\n",
    "women_odi['Matches']=women_matches\n",
    "women_odi['Points']=women_points\n",
    "women_odi['Ratings']=women_ratings\n",
    "women_odi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_odi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page9 = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "page9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page9.content)\n",
    "soup =  BeautifulSoup(page9.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_players_name = [] #empty list\n",
    "women_team_name = [] #empty list\n",
    "women_rating = [] #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mithali Raj',\n",
       " 'Lizelle Lee',\n",
       " 'Alyssa Healy',\n",
       " 'Tammy Beaumont',\n",
       " 'Stafanie Taylor',\n",
       " 'Meg Lanning',\n",
       " 'Amy Satterthwaite',\n",
       " 'Natalie Sciver',\n",
       " 'Smriti Mandhana',\n",
       " 'Laura Wolvaardt']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape players\n",
    "player_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\")  #first place player name\n",
    "\n",
    "women_players_name = [] #empty list\n",
    "for i in player_1:\n",
    "    women_players_name.append(i.text)\n",
    "\n",
    "other_players = soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")  # other players\n",
    "\n",
    "for i in other_players:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        women_players_name.append(j.text)\n",
    "women_players_name = women_players_name[:10]\n",
    "women_players_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_players_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IND', 'SA', 'AUS', 'ENG', 'WI', 'AUS', 'NZ', 'ENG', 'IND', 'SA']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape team name\n",
    "team_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\")   #first place team name\n",
    "\n",
    "women_team_name = []  #empty list\n",
    "for i in team_1:\n",
    "    women_team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "other_teams = soup.find_all(\"span\",class_=\"table-body__logo-text\")  # other teams name\n",
    "\n",
    "for i in other_teams:\n",
    "    women_team_name.append(i.text)\n",
    "women_team_name = women_team_name[:10]\n",
    "women_team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['762', '758', '756', '754', '736', '723', '715', '706', '701', '683']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape ratings\n",
    "rating_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--rating\")    #first place player ratings\n",
    "\n",
    "women_rating = []  #empty list\n",
    "for i in rating_1:\n",
    "    women_rating.append(i.text)\n",
    "\n",
    "others_ratings = soup.find_all(\"td\",class_=\"table-body__cell rating\")      #other players ratings\n",
    "\n",
    "for i in others_ratings:\n",
    "    women_rating.append(i.text)\n",
    "women_rating = women_rating[:10]\n",
    "women_rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(women_players_name),len(women_team_name),len(women_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0        Mithali Raj  IND    762\n",
       "1        Lizelle Lee   SA    758\n",
       "2       Alyssa Healy  AUS    756\n",
       "3     Tammy Beaumont  ENG    754\n",
       "4    Stafanie Taylor   WI    736\n",
       "5        Meg Lanning  AUS    723\n",
       "6  Amy Satterthwaite   NZ    715\n",
       "7     Natalie Sciver  ENG    706\n",
       "8    Smriti Mandhana  IND    701\n",
       "9    Laura Wolvaardt   SA    683"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of top 10 Women's ODI Batting Rankings\n",
    "women_top_players=pd.DataFrame({})\n",
    "women_top_players['Player']=women_players_name\n",
    "women_top_players['Team']=women_team_name\n",
    "women_top_players['Rating']=women_rating\n",
    "women_top_players[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_top_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page10 = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "page10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page10.content)\n",
    "soup =  BeautifulSoup(page10.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_all_rounders = [] #empty list\n",
    "women_team_name = [] #empty list  \n",
    "women_rating = [] #empty list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marizanne Kapp',\n",
       " 'Ellyse Perry',\n",
       " 'Stafanie Taylor',\n",
       " 'Natalie Sciver',\n",
       " 'Deepti Sharma',\n",
       " 'Jess Jonassen',\n",
       " 'Ashleigh Gardner',\n",
       " 'Dane van Niekerk',\n",
       " 'Sophie Devine',\n",
       " 'Katherine Brunt']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape top 10 all-rounders name\n",
    "all_rounder_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\")   #first place all-rounder name\n",
    "\n",
    "women_all_rounders = []   #empty list\n",
    "for i in all_rounder_1:\n",
    "    women_all_rounders.append(i.text)\n",
    "\n",
    "other_all_rounders = soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")   #other all-rounders name\n",
    "\n",
    "for i in other_all_rounders:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        women_all_rounders.append(j.text)\n",
    "women_all_rounders = women_all_rounders[:10]\n",
    "women_all_rounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_all_rounders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'AUS', 'WI', 'ENG', 'IND', 'AUS', 'AUS', 'SA', 'NZ', 'ENG']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape team name\n",
    "team_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\")  # first place all-rounder team name\n",
    "\n",
    "women_team_name = []   #empty list\n",
    "for i in team_1:\n",
    "    women_team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "other_teams = soup.find_all(\"span\",class_=\"table-body__logo-text\")   # other all-rounders team name\n",
    "\n",
    "for i in other_teams:\n",
    "    women_team_name.append(i.text)\n",
    "women_team_name = women_team_name[:10]\n",
    "women_team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['418', '418', '394', '365', '331', '307', '252', '243', '242', '239']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape ratings\n",
    "rating_1 = soup.find_all(\"div\",class_=\"rankings-block__banner--rating\")   # first place bowler ratings\n",
    "\n",
    "women_ratings = []   #empty list\n",
    "for i in rating_1:\n",
    "    women_ratings.append(i.text)\n",
    "\n",
    "others_ratings = soup.find_all(\"td\",class_=\"table-body__cell rating\")   # other bowlers ratings\n",
    "\n",
    "for i in others_ratings:\n",
    "    women_ratings.append(i.text)\n",
    "women_ratings = women_ratings[:10]\n",
    "women_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(women_all_rounders),len(women_team_name),len(women_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Players Team Rating\n",
       "0    Marizanne Kapp   SA    418\n",
       "1      Ellyse Perry  AUS    418\n",
       "2   Stafanie Taylor   WI    394\n",
       "3    Natalie Sciver  ENG    365\n",
       "4     Deepti Sharma  IND    331\n",
       "5     Jess Jonassen  AUS    307\n",
       "6  Ashleigh Gardner  AUS    252\n",
       "7  Dane van Niekerk   SA    243\n",
       "8     Sophie Devine   NZ    242\n",
       "9   Katherine Brunt  ENG    239"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of top 10 Women's ODI All-Rounder Rankings\n",
    "all_rounder=pd.DataFrame({})\n",
    "all_rounder['Players']=women_all_rounders\n",
    "all_rounder['Team']=women_team_name\n",
    "all_rounder['Rating']=women_ratings\n",
    "all_rounder[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_rounder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://www.amazon.in/s?k=Mobile+phones+under+20000&ref=nb_sb_noss_2\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup =  BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name = []  #empty list\n",
    "product_price = []    #empty list\n",
    "image_url = []   #empty list\n",
    "product_rating = []   #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>Image_url</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....</td>\n",
       "      <td>8,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61CnyJ-IbM...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...</td>\n",
       "      <td>11,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/710jkZNub3...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71X5I1cVfb...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716nHhG9SW...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy M31s (Mirage Blue, 6GB RAM, 128...</td>\n",
       "      <td>12,490</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61d-phh4Gf...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OPPO A31 (Mystery Black, 4GB RAM, 64GB Storage...</td>\n",
       "      <td>10,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Redmi Note 10 (Frost White, 4GB RAM, 64GB Stor...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71SSmaLA7x...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Samsung Galaxy M12 (Black,4GB RAM, 64GB Storag...</td>\n",
       "      <td>13,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/714QWDxXgN...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Redmi Note 10 (Shadow Black, 4GB RAM, 64GB Sto...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QY6JV6Fh...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Redmi 9A (Midnight Black 2GB RAM 32GB Storage)...</td>\n",
       "      <td>13,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Samsung Galaxy M12 (Black,6GB RAM, 128GB Stora...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/714QWDxXgN...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Redmi Note 10S (Frost White, 6GB RAM, 64GB Sto...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71BiT9Cqz+...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Samsung Galaxy M12 (Blue,6GB RAM, 128GB Storag...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71yYaNztZ0...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         product_name   price  \\\n",
       "0   Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...   6,999   \n",
       "1   Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....   8,999   \n",
       "2   Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...   9,999   \n",
       "3   Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...  11,499   \n",
       "4   Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...   8,999   \n",
       "5   Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...  12,999   \n",
       "6   Samsung Galaxy M31s (Mirage Blue, 6GB RAM, 128...  12,490   \n",
       "7   OPPO A31 (Mystery Black, 4GB RAM, 64GB Storage...  10,999   \n",
       "8   Redmi Note 10 (Frost White, 4GB RAM, 64GB Stor...  12,999   \n",
       "9   Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...   6,999   \n",
       "10  Samsung Galaxy M12 (Black,4GB RAM, 64GB Storag...  13,499   \n",
       "11  Redmi Note 10 (Shadow Black, 4GB RAM, 64GB Sto...  14,999   \n",
       "12  Redmi 9A (Midnight Black 2GB RAM 32GB Storage)...  13,499   \n",
       "13  Samsung Galaxy M12 (Black,6GB RAM, 128GB Stora...   6,999   \n",
       "14  Redmi Note 10S (Frost White, 6GB RAM, 64GB Sto...   8,999   \n",
       "15  Samsung Galaxy M12 (Blue,6GB RAM, 128GB Storag...   9,999   \n",
       "\n",
       "                                            Image_url              Rating  \n",
       "0   https://m.media-amazon.com/images/I/71sxlhYhKW...  4.2 out of 5 stars  \n",
       "1   https://m.media-amazon.com/images/I/71A9Vo1Bat...  4.2 out of 5 stars  \n",
       "2   https://m.media-amazon.com/images/I/61CnyJ-IbM...  4.2 out of 5 stars  \n",
       "3   https://m.media-amazon.com/images/I/710jkZNub3...  4.1 out of 5 stars  \n",
       "4   https://m.media-amazon.com/images/I/71X5I1cVfb...  4.3 out of 5 stars  \n",
       "5   https://m.media-amazon.com/images/I/716nHhG9SW...  4.2 out of 5 stars  \n",
       "6   https://m.media-amazon.com/images/I/61d-phh4Gf...  4.3 out of 5 stars  \n",
       "7   https://m.media-amazon.com/images/I/71KCwNV6Mu...  4.2 out of 5 stars  \n",
       "8   https://m.media-amazon.com/images/I/71SSmaLA7x...  4.1 out of 5 stars  \n",
       "9   https://m.media-amazon.com/images/I/71KCwNV6Mu...  4.2 out of 5 stars  \n",
       "10  https://m.media-amazon.com/images/I/714QWDxXgN...  4.1 out of 5 stars  \n",
       "11  https://m.media-amazon.com/images/I/71QY6JV6Fh...  4.1 out of 5 stars  \n",
       "12  https://m.media-amazon.com/images/I/71sxlhYhKW...  4.2 out of 5 stars  \n",
       "13  https://m.media-amazon.com/images/I/714QWDxXgN...  4.1 out of 5 stars  \n",
       "14  https://m.media-amazon.com/images/I/71BiT9Cqz+...  4.0 out of 5 stars  \n",
       "15  https://m.media-amazon.com/images/I/71yYaNztZ0...  4.1 out of 5 stars  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape product name\n",
    "name = soup.find_all(\"span\",class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "for i in name:\n",
    "    product_name.append(i.text)\n",
    "\n",
    "# Scrape product price\n",
    "price = soup.find_all(\"span\",class_=\"a-price-whole\")\n",
    "for i in price:\n",
    "    product_price.append(i.text)\n",
    "\n",
    "# Scrape images url\n",
    "image = soup.find_all(\"img\",class_=\"s-image\")\n",
    "for i in image:\n",
    "    image_url.append(i.get(\"src\"))\n",
    "\n",
    "\n",
    "# Scrape product ratings\n",
    "rating = soup.find_all(\"i\",class_=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\")\n",
    "for i in rating:\n",
    "    product_rating.append(i.text)\n",
    "    \n",
    "# Make data frame of mobile phones under Rs. 20,000 listed on Amazon.in\n",
    "mobile_phones=pd.DataFrame({})\n",
    "mobile_phones['product_name']=product_name[:16]\n",
    "mobile_phones['price']=product_price[:16]\n",
    "mobile_phones['Image_url'] =image_url[:16]\n",
    "mobile_phones['Rating']=product_rating[:16]\n",
    "\n",
    "mobile_phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mobile_phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YQD0944zZPY\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup =  BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = []      #empty list\n",
    "short_desc = []   #empty list\n",
    "temperature = []   #empty list\n",
    "description = []    #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tonight',\n",
       " 'Wednesday',\n",
       " 'WednesdayNight',\n",
       " 'Thursday',\n",
       " 'ThursdayNight',\n",
       " 'Friday',\n",
       " 'FridayNight',\n",
       " 'Saturday',\n",
       " 'SaturdayNight']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape period\n",
    "prd = soup.find_all(\"p\", class_=\"period-name\")\n",
    "\n",
    "period = []      #empty list\n",
    "for i in prd:\n",
    "    period.append(i.text)\n",
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partly Cloudy',\n",
       " 'Mostly Sunnythen MostlySunny andBreezy',\n",
       " 'Partly Cloudyand Breezythen MostlyCloudy',\n",
       " 'Partly Sunnythen Sunnyand Breezy',\n",
       " 'Mostly Clearand Breezythen PartlyCloudy',\n",
       " 'Mostly Sunnythen Sunnyand Breezy',\n",
       " 'Partly Cloudyand Breezythen MostlyCloudy',\n",
       " 'Partly Sunny',\n",
       " 'Mostly Cloudy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape short description\n",
    "short_description = soup.find_all('p',class_=\"short-desc\")\n",
    "\n",
    "short_desc = [] #empty list\n",
    "for i in short_description:\n",
    "    short_desc.append(i.text)\n",
    "short_desc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Low: 56 °F',\n",
       " 'High: 71 °F',\n",
       " 'Low: 57 °F',\n",
       " 'High: 70 °F',\n",
       " 'Low: 56 °F',\n",
       " 'High: 70 °F',\n",
       " 'Low: 56 °F',\n",
       " 'High: 67 °F',\n",
       " 'Low: 56 °F']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape temperature\n",
    "temp = soup.find_all('p',attrs={'short-desc'})\n",
    "\n",
    "temperature = []  #empty list\n",
    "for i in temp:\n",
    "    if i.next_sibling is not None:\n",
    "        temperature.append(i.next_sibling.text)\n",
    "    else:\n",
    "        temperature.append(' ')\n",
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partly cloudy, with a low around 56. West southwest wind 13 to 18 mph, with gusts as high as 24 mph. ',\n",
       " 'Mostly sunny, with a high near 71. Breezy, with a west southwest wind 11 to 16 mph increasing to 19 to 24 mph in the afternoon. Winds could gust as high as 31 mph. ',\n",
       " 'Mostly cloudy, with a low around 57. Breezy, with a west southwest wind 20 to 25 mph decreasing to 14 to 19 mph after midnight. Winds could gust as high as 33 mph. ',\n",
       " 'Mostly cloudy, then gradually becoming sunny, with a high near 70. Breezy, with a west southwest wind 11 to 16 mph increasing to 18 to 23 mph in the afternoon. Winds could gust as high as 30 mph. ',\n",
       " 'Partly cloudy, with a low around 56. Breezy, with a west southwest wind 14 to 23 mph, with gusts as high as 31 mph. ',\n",
       " 'Mostly sunny, with a high near 70. Breezy. ',\n",
       " 'Mostly cloudy, with a low around 56. Breezy. ',\n",
       " 'Partly sunny, with a high near 67.',\n",
       " 'Mostly cloudy, with a low around 56.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape description\n",
    "desc = soup.find_all(\"div\",class_=\"col-sm-10 forecast-text\")\n",
    "\n",
    "description = []  #empty list\n",
    "for i in desc:\n",
    "    description.append(i.text)\n",
    "description = description[:9]\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Short_description</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 56. West sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Mostly Sunnythen MostlySunny andBreezy</td>\n",
       "      <td>Mostly sunny, with a high near 71. Breezy, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Mostly cloudy, with a low around 57. Breezy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>High: 70 °F</td>\n",
       "      <td>Partly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Partly cloudy, with a low around 56. Breezy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Friday</td>\n",
       "      <td>High: 70 °F</td>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>Mostly sunny, with a high near 70. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Mostly cloudy, with a low around 56. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>High: 67 °F</td>\n",
       "      <td>Partly Sunny</td>\n",
       "      <td>Partly sunny, with a high near 67.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>Mostly cloudy, with a low around 56.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period  Temperature                         Short_description  \\\n",
       "0         Tonight   Low: 56 °F                             Partly Cloudy   \n",
       "1       Wednesday  High: 71 °F    Mostly Sunnythen MostlySunny andBreezy   \n",
       "2  WednesdayNight   Low: 57 °F  Partly Cloudyand Breezythen MostlyCloudy   \n",
       "3        Thursday  High: 70 °F          Partly Sunnythen Sunnyand Breezy   \n",
       "4   ThursdayNight   Low: 56 °F   Mostly Clearand Breezythen PartlyCloudy   \n",
       "5          Friday  High: 70 °F          Mostly Sunnythen Sunnyand Breezy   \n",
       "6     FridayNight   Low: 56 °F  Partly Cloudyand Breezythen MostlyCloudy   \n",
       "7        Saturday  High: 67 °F                              Partly Sunny   \n",
       "8   SaturdayNight   Low: 56 °F                             Mostly Cloudy   \n",
       "\n",
       "                                         Description  \n",
       "0  Partly cloudy, with a low around 56. West sout...  \n",
       "1  Mostly sunny, with a high near 71. Breezy, wit...  \n",
       "2  Mostly cloudy, with a low around 57. Breezy, w...  \n",
       "3  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "4  Partly cloudy, with a low around 56. Breezy, w...  \n",
       "5        Mostly sunny, with a high near 70. Breezy.   \n",
       "6      Mostly cloudy, with a low around 56. Breezy.   \n",
       "7                 Partly sunny, with a high near 67.  \n",
       "8               Mostly cloudy, with a low around 56.  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame\n",
    "san_francisco_weather=pd.DataFrame({})\n",
    "san_francisco_weather['Period']=period\n",
    "san_francisco_weather['Temperature']=temperature\n",
    "san_francisco_weather['Short_description']=short_desc\n",
    "san_francisco_weather['Description']=description\n",
    "san_francisco_weather[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(san_francisco_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9.Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://internshala.com/fresher-jobs\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup =  BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []  #empty list\n",
    "company_names = []   #empty list\n",
    "CTC = []   #empty list\n",
    "apply_date = []    #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sales Manager/Omni Sport Leader - Retail ',\n",
       " 'Data Analyst ',\n",
       " 'Software Tester ',\n",
       " 'Business Development Executive ',\n",
       " 'MERN Stack Developer ',\n",
       " 'Conversion Rate Optimization Analyst ',\n",
       " 'Client Service Executive ',\n",
       " 'Sales Development Representative ',\n",
       " 'Corporate Sales Associate ',\n",
       " 'International Business Development Executive ',\n",
       " 'Product Marketer ',\n",
       " 'Customer Support Associates ',\n",
       " 'Content & Customer Care Executive ',\n",
       " 'Django Developer ',\n",
       " 'Reactjs Developer ',\n",
       " 'Web Development Trainee ',\n",
       " 'Business Development Executive ',\n",
       " 'Cybersecurity Compliance Officer ',\n",
       " 'MERN Stack Developer ',\n",
       " 'Senior Copywriter ',\n",
       " 'Corporate Sales Associate ',\n",
       " 'Digital Marketing Associate ',\n",
       " 'Social Media Marketing Executive ',\n",
       " 'Business Development Executive ',\n",
       " 'Operations Manager ',\n",
       " 'Lead Counselor ',\n",
       " 'Angular.js Developer ',\n",
       " 'Digital Marketing Specialist ',\n",
       " 'Franchise Manager - Sales (Assistant Manager ) ',\n",
       " 'Graphic Designer ',\n",
       " 'Project Associate ',\n",
       " 'Business Development Manager ',\n",
       " 'Associate Recruiter ',\n",
       " 'Inside Sales Specialist ',\n",
       " 'QA Tester ',\n",
       " 'Social Media Marketing Specialist ',\n",
       " 'Sales Executive ',\n",
       " 'Data & BI Consultant ',\n",
       " 'Full Stack Developer ',\n",
       " 'Business Development Executive ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles=soup.find_all('div',class_=\"heading_4_5 profile\") \n",
    "\n",
    "job_titles=[] # empty list\n",
    "for i in titles:\n",
    "    job_titles.append(i.text.replace('\\n',''))\n",
    "job_titles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Decathlon Sport India Private Limited',\n",
       " 'Anudeep Nekkanti',\n",
       " 'Startxlabs Technologies Private Limited',\n",
       " 'Padhhigh',\n",
       " 'Snippt',\n",
       " 'DataVinci Private Limited',\n",
       " 'Red Tree Design Studio Private Limited',\n",
       " 'HelloAR',\n",
       " 'Best Roadways Limited',\n",
       " 'Advids',\n",
       " 'Habitate Technologies Private Limited',\n",
       " 'Recruit CRM',\n",
       " 'Revo International LLP',\n",
       " 'Startxlabs Technologies Private Limited',\n",
       " 'Startxlabs Technologies Private Limited',\n",
       " 'Softsensor.ai',\n",
       " 'Verzeo',\n",
       " 'S3 Infosoft',\n",
       " 'Binary Numbers',\n",
       " 'Ranksoldier International Private Limited',\n",
       " 'MiM-Essay',\n",
       " 'BubbleNut Wash',\n",
       " 'Erikka India',\n",
       " 'Cosmic Micro Systems Private Limited',\n",
       " 'Kumi Labs',\n",
       " 'HOSS - House Of Soft Skills',\n",
       " 'Systaldyn Consultancy Private Limited',\n",
       " 'Sahadya Consultants',\n",
       " 'Regrob',\n",
       " 'Cynfas',\n",
       " 'StrategyCo.Global',\n",
       " 'Narsipur Chemicals Private Limited',\n",
       " 'Talhive',\n",
       " 'UniHyr',\n",
       " 'RavGins International Private Limited (Wobb.ai)',\n",
       " 'Zolve',\n",
       " 'Apt Medical Systems Private Limited',\n",
       " 'CloudGarage',\n",
       " 'PeakMind',\n",
       " 'Cafe Tatva Ventures LLP']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape company names    \n",
    "companies=soup.find_all('a',class_=\"link_display_like_text\")\n",
    "\n",
    "company_names = []  # empty list\n",
    "for i in companies:\n",
    "    company_names.append(i.text.strip())\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.3 - 4.5 LPA',\n",
       " '6 - 10 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '4 - 7 LPA',\n",
       " '4 - 5 LPA',\n",
       " '5 LPA',\n",
       " '3 LPA',\n",
       " '3 - 3.2 LPA',\n",
       " '3 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3.2 - 4.2 LPA',\n",
       " '5 - 7 LPA',\n",
       " '3 - 3.05 LPA',\n",
       " '3.5 - 7.5 LPA',\n",
       " '3.5 - 7.5 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 6 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '3 - 7 LPA',\n",
       " '3 LPA',\n",
       " '4.5 - 6 LPA',\n",
       " '3.6 - 5.4 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 4.8 LPA',\n",
       " '3 - 8 LPA',\n",
       " '3.8 - 4.5 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '3 - 3.1 LPA',\n",
       " '3 LPA',\n",
       " '7 - 12 LPA',\n",
       " '5 - 7 LPA',\n",
       " '3 - 5 LPA',\n",
       " '5 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 8 LPA',\n",
       " '3 LPA',\n",
       " '3 LPA',\n",
       " '6 - 8 LPA',\n",
       " '3 - 5.5 LPA']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape CTC\n",
    "info = soup.find_all(\"div\",class_=\"item_body\")\n",
    "\n",
    "job_info = []\n",
    "for i in info:\n",
    "    job_info.append(i.text.replace(\"\\n\",\"\").replace(\"\\xa0\",\"\"))\n",
    "\n",
    "CTC = []  #empty list\n",
    "for i in range(1,len(job_info),3):\n",
    "    CTC.append(job_info[i].strip())\n",
    "\n",
    "CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"21 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\",\n",
       " \"21 Aug' 21\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape allpy date\n",
    "app_date = soup.find_all(\"div\",class_=\"item_body\")\n",
    "apply_date = []  # empty list\n",
    "for i in range(2,len(job_info),3):\n",
    "    apply_date.append(job_info[i].strip())\n",
    "apply_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apply_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(CTC),len(apply_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Titles</th>\n",
       "      <th>Company_Names</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales Manager/Omni Sport Leader - Retail</td>\n",
       "      <td>Decathlon Sport India Private Limited</td>\n",
       "      <td>3.3 - 4.5 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Anudeep Nekkanti</td>\n",
       "      <td>6 - 10 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Tester</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Padhhigh</td>\n",
       "      <td>4 - 7 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MERN Stack Developer</td>\n",
       "      <td>Snippt</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Conversion Rate Optimization Analyst</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>5 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Client Service Executive</td>\n",
       "      <td>Red Tree Design Studio Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>HelloAR</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Business Development Executive</td>\n",
       "      <td>Advids</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>3.2 - 4.2 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Customer Support Associates</td>\n",
       "      <td>Recruit CRM</td>\n",
       "      <td>5 - 7 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Content &amp; Customer Care Executive</td>\n",
       "      <td>Revo International LLP</td>\n",
       "      <td>3 - 3.05 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Django Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3.5 - 7.5 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3.5 - 7.5 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Web Development Trainee</td>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Verzeo</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cybersecurity Compliance Officer</td>\n",
       "      <td>S3 Infosoft</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MERN Stack Developer</td>\n",
       "      <td>Binary Numbers</td>\n",
       "      <td>3 - 7 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Senior Copywriter</td>\n",
       "      <td>Ranksoldier International Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>MiM-Essay</td>\n",
       "      <td>4.5 - 6 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Digital Marketing Associate</td>\n",
       "      <td>BubbleNut Wash</td>\n",
       "      <td>3.6 - 5.4 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Social Media Marketing Executive</td>\n",
       "      <td>Erikka India</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Cosmic Micro Systems Private Limited</td>\n",
       "      <td>3 - 4.8 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Operations Manager</td>\n",
       "      <td>Kumi Labs</td>\n",
       "      <td>3 - 8 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lead Counselor</td>\n",
       "      <td>HOSS - House Of Soft Skills</td>\n",
       "      <td>3.8 - 4.5 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Angular.js Developer</td>\n",
       "      <td>Systaldyn Consultancy Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Sahadya Consultants</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Franchise Manager - Sales (Assistant Manager )</td>\n",
       "      <td>Regrob</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>Cynfas</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Project Associate</td>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>7 - 12 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>Narsipur Chemicals Private Limited</td>\n",
       "      <td>5 - 7 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Associate Recruiter</td>\n",
       "      <td>Talhive</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Inside Sales Specialist</td>\n",
       "      <td>UniHyr</td>\n",
       "      <td>5 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>QA Tester</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Social Media Marketing Specialist</td>\n",
       "      <td>Zolve</td>\n",
       "      <td>3 - 8 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>Apt Medical Systems Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Data &amp; BI Consultant</td>\n",
       "      <td>CloudGarage</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>PeakMind</td>\n",
       "      <td>6 - 8 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Cafe Tatva Ventures LLP</td>\n",
       "      <td>3 - 5.5 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_Titles  \\\n",
       "0         Sales Manager/Omni Sport Leader - Retail    \n",
       "1                                     Data Analyst    \n",
       "2                                  Software Tester    \n",
       "3                   Business Development Executive    \n",
       "4                             MERN Stack Developer    \n",
       "5             Conversion Rate Optimization Analyst    \n",
       "6                         Client Service Executive    \n",
       "7                 Sales Development Representative    \n",
       "8                        Corporate Sales Associate    \n",
       "9     International Business Development Executive    \n",
       "10                                Product Marketer    \n",
       "11                     Customer Support Associates    \n",
       "12               Content & Customer Care Executive    \n",
       "13                                Django Developer    \n",
       "14                               Reactjs Developer    \n",
       "15                         Web Development Trainee    \n",
       "16                  Business Development Executive    \n",
       "17                Cybersecurity Compliance Officer    \n",
       "18                            MERN Stack Developer    \n",
       "19                               Senior Copywriter    \n",
       "20                       Corporate Sales Associate    \n",
       "21                     Digital Marketing Associate    \n",
       "22                Social Media Marketing Executive    \n",
       "23                  Business Development Executive    \n",
       "24                              Operations Manager    \n",
       "25                                  Lead Counselor    \n",
       "26                            Angular.js Developer    \n",
       "27                    Digital Marketing Specialist    \n",
       "28  Franchise Manager - Sales (Assistant Manager )    \n",
       "29                                Graphic Designer    \n",
       "30                               Project Associate    \n",
       "31                    Business Development Manager    \n",
       "32                             Associate Recruiter    \n",
       "33                         Inside Sales Specialist    \n",
       "34                                       QA Tester    \n",
       "35               Social Media Marketing Specialist    \n",
       "36                                 Sales Executive    \n",
       "37                            Data & BI Consultant    \n",
       "38                            Full Stack Developer    \n",
       "39                  Business Development Executive    \n",
       "\n",
       "                                      Company_Names            CTC  Apply_Date  \n",
       "0             Decathlon Sport India Private Limited  3.3 - 4.5 LPA  21 Aug' 21  \n",
       "1                                  Anudeep Nekkanti     6 - 10 LPA  27 Aug' 21  \n",
       "2           Startxlabs Technologies Private Limited    3 - 3.6 LPA  27 Aug' 21  \n",
       "3                                          Padhhigh      4 - 7 LPA  26 Aug' 21  \n",
       "4                                            Snippt      4 - 5 LPA  26 Aug' 21  \n",
       "5                         DataVinci Private Limited          5 LPA  26 Aug' 21  \n",
       "6            Red Tree Design Studio Private Limited          3 LPA  26 Aug' 21  \n",
       "7                                           HelloAR    3 - 3.2 LPA  26 Aug' 21  \n",
       "8                             Best Roadways Limited          3 LPA  26 Aug' 21  \n",
       "9                                            Advids      3 - 4 LPA  26 Aug' 21  \n",
       "10            Habitate Technologies Private Limited  3.2 - 4.2 LPA  25 Aug' 21  \n",
       "11                                      Recruit CRM      5 - 7 LPA  25 Aug' 21  \n",
       "12                           Revo International LLP   3 - 3.05 LPA  25 Aug' 21  \n",
       "13          Startxlabs Technologies Private Limited  3.5 - 7.5 LPA  25 Aug' 21  \n",
       "14          Startxlabs Technologies Private Limited  3.5 - 7.5 LPA  25 Aug' 21  \n",
       "15                                    Softsensor.ai      3 - 5 LPA  25 Aug' 21  \n",
       "16                                           Verzeo      3 - 6 LPA  25 Aug' 21  \n",
       "17                                      S3 Infosoft    3 - 3.6 LPA  25 Aug' 21  \n",
       "18                                   Binary Numbers      3 - 7 LPA  23 Aug' 21  \n",
       "19        Ranksoldier International Private Limited          3 LPA  23 Aug' 21  \n",
       "20                                        MiM-Essay    4.5 - 6 LPA  25 Aug' 21  \n",
       "21                                   BubbleNut Wash  3.6 - 5.4 LPA  23 Aug' 21  \n",
       "22                                     Erikka India      3 - 5 LPA  23 Aug' 21  \n",
       "23             Cosmic Micro Systems Private Limited    3 - 4.8 LPA  22 Aug' 21  \n",
       "24                                        Kumi Labs      3 - 8 LPA  25 Aug' 21  \n",
       "25                      HOSS - House Of Soft Skills  3.8 - 4.5 LPA  22 Aug' 21  \n",
       "26            Systaldyn Consultancy Private Limited      3 - 5 LPA  22 Aug' 21  \n",
       "27                              Sahadya Consultants    3 - 3.5 LPA  22 Aug' 21  \n",
       "28                                           Regrob    3 - 3.1 LPA  22 Aug' 21  \n",
       "29                                           Cynfas          3 LPA  22 Aug' 21  \n",
       "30                                StrategyCo.Global     7 - 12 LPA  21 Aug' 21  \n",
       "31               Narsipur Chemicals Private Limited      5 - 7 LPA  21 Aug' 21  \n",
       "32                                          Talhive      3 - 5 LPA  21 Aug' 21  \n",
       "33                                           UniHyr          5 LPA  21 Aug' 21  \n",
       "34  RavGins International Private Limited (Wobb.ai)      3 - 4 LPA  21 Aug' 21  \n",
       "35                                            Zolve      3 - 8 LPA  21 Aug' 21  \n",
       "36              Apt Medical Systems Private Limited          3 LPA  21 Aug' 21  \n",
       "37                                      CloudGarage          3 LPA  21 Aug' 21  \n",
       "38                                         PeakMind      6 - 8 LPA  21 Aug' 21  \n",
       "39                          Cafe Tatva Ventures LLP    3 - 5.5 LPA  21 Aug' 21  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame\n",
    "Freshers_job=pd.DataFrame({})\n",
    "Freshers_job['Job_Titles']=job_titles\n",
    "Freshers_job['Company_Names']=company_names\n",
    "Freshers_job['CTC']=CTC\n",
    "Freshers_job['Apply_Date']=apply_date\n",
    "Freshers_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Freshers_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see content in page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup =  BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_title = []  #empty list\n",
    "location = []  #empty list\n",
    "Area = []  #empty list\n",
    "EMI = []   #empty list\n",
    "price = []   #empty list\n",
    "\n",
    "\n",
    "#scrape house title \n",
    "house = soup14.find_all(\"h2\", class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "for i in house:\n",
    "    house_title.append(i.text)\n",
    "    \n",
    "#scrape house location     \n",
    "loc = soup.find_all('div',class_=\"nb__2CMjv\")\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "    \n",
    "#scrape house Area     \n",
    "area = soup.find_all('div',class_=\"nb__3oNyC\")\n",
    "for i in area:\n",
    "    Area.append(i.text)\n",
    "    \n",
    "\n",
    "full_info = []\n",
    "detail = soup14.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "for i in detail:\n",
    "    full_info.append(i.text)\n",
    "\n",
    "#EMI\n",
    "for i in range(1,len(full_info),3):\n",
    "    EMI.append(full_info[i])\n",
    "\n",
    "# price\n",
    "for i in range(2,len(full_info),3):\n",
    "    price.append(full_info[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 BHK For Sale  In Gpr Royale In Gpr Royale ',\n",
       " '4 BHK Flat  For Sale  In Electronic City ',\n",
       " '4 BHK Flat  For Sale  In Sobha Silicon Oasis  In Hosa Road ',\n",
       " '4 BHK In Independent House  For Sale  In Sarjapura ',\n",
       " '4 BHK In Independent House  For Sale  In Naganathapura ',\n",
       " '4 BHK For Sale  In Daadys Garden In Electronic City ',\n",
       " '4 BHK For Sale  In Deccan Palms Park In Electronic City ',\n",
       " '4 BHK In Independent House  For Sale  In Parappana Agrahara ',\n",
       " '4 BHK In Independent House  For Sale  In Electronic City,  ',\n",
       " '4 BHK In Independent House  For Sale  In Electronic City Phase Ii ']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(house_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6th Cross',\n",
       " 'Standalone Building, Shikaripalya near Shams School',\n",
       " 'Sobha Silicon Oasis Naganathapura, Rayasandra Bengaluru, Karnataka 560100 India',\n",
       " 'Independent House,  Shantipura Village , S.P Layout , near  Shantipura Panchayat Office',\n",
       " 'Independent House, Doddanagamangala Rd opposite Sobha Silicon Oasis',\n",
       " 'Daadys GardenÂ\\xa0 Kammasandra Rd, Kammasandra, Electronic City, Bengaluru, Karnataka 560100, India',\n",
       " 'Deccan Palms ParkÂ\\xa0 Deccan Palms Villas, Deccan Palms Road, Shree Ananth Nagar Layout, Glass Factory Layout, Electronic City, Bengaluru, Karnataka 560100, India',\n",
       " 'Independent House, Hosur Road CK Nagar near Shri Shakthi Mariyamma Temple',\n",
       " 'Independent House,  Krishna reddy layout-Near Maruti Suzuki ARENA (Surakshaa Car Care, Bengaluru, Electronic City)',\n",
       " 'Independent House, Industrial Area Near Tech Mahindra']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,100 sqft',\n",
       " '1,400 sqft',\n",
       " '1,879 sqft',\n",
       " '1,100 sqft',\n",
       " '1,500 sqft',\n",
       " '2,600 sqft',\n",
       " '3,000 sqft',\n",
       " '1,000 sqft',\n",
       " '2,500 sqft',\n",
       " '1,500 sqft']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹85,971/Month',\n",
       " '₹20,060/Month',\n",
       " '₹85,971/Month',\n",
       " '₹40,120/Month',\n",
       " '₹45,851/Month',\n",
       " '₹85,971/Month',\n",
       " '₹85,971/Month',\n",
       " '₹37,254/Month',\n",
       " '₹1.43 Lacs/Month',\n",
       " '₹57,314/Month']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1.5 Crores',\n",
       " '₹35 Lacs',\n",
       " '₹1.5 Crores',\n",
       " '₹70 Lacs',\n",
       " '₹80 Lacs',\n",
       " '₹1.5 Crores',\n",
       " '₹1.5 Crores',\n",
       " '₹65 Lacs',\n",
       " '₹2.5 Crores',\n",
       " '₹1 Crore']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(house_title),len(location),len(Area),len(EMI),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House</th>\n",
       "      <th>Area</th>\n",
       "      <th>location</th>\n",
       "      <th>EMI</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK For Sale  In Gpr Royale In Gpr Royale</td>\n",
       "      <td>3,100 sqft</td>\n",
       "      <td>6th Cross</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>Standalone Building, Shikaripalya near Shams S...</td>\n",
       "      <td>₹20,060/Month</td>\n",
       "      <td>₹35 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...</td>\n",
       "      <td>1,879 sqft</td>\n",
       "      <td>Sobha Silicon Oasis Naganathapura, Rayasandra ...</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Sarja...</td>\n",
       "      <td>1,100 sqft</td>\n",
       "      <td>Independent House,  Shantipura Village , S.P L...</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Nagan...</td>\n",
       "      <td>1,500 sqft</td>\n",
       "      <td>Independent House, Doddanagamangala Rd opposit...</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK For Sale  In Daadys Garden In Electronic...</td>\n",
       "      <td>2,600 sqft</td>\n",
       "      <td>Daadys GardenÂ  Kammasandra Rd, Kammasandra, E...</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK For Sale  In Deccan Palms Park In Electr...</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>Deccan Palms ParkÂ  Deccan Palms Villas, Decca...</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Parap...</td>\n",
       "      <td>1,000 sqft</td>\n",
       "      <td>Independent House, Hosur Road CK Nagar near Sh...</td>\n",
       "      <td>₹37,254/Month</td>\n",
       "      <td>₹65 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>2,500 sqft</td>\n",
       "      <td>Independent House,  Krishna reddy layout-Near ...</td>\n",
       "      <td>₹1.43 Lacs/Month</td>\n",
       "      <td>₹2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>1,500 sqft</td>\n",
       "      <td>Independent House, Industrial Area Near Tech M...</td>\n",
       "      <td>₹57,314/Month</td>\n",
       "      <td>₹1 Crore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               House        Area  \\\n",
       "0       4 BHK For Sale  In Gpr Royale In Gpr Royale   3,100 sqft   \n",
       "1          4 BHK Flat  For Sale  In Electronic City   1,400 sqft   \n",
       "2  4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...  1,879 sqft   \n",
       "3  4 BHK In Independent House  For Sale  In Sarja...  1,100 sqft   \n",
       "4  4 BHK In Independent House  For Sale  In Nagan...  1,500 sqft   \n",
       "5  4 BHK For Sale  In Daadys Garden In Electronic...  2,600 sqft   \n",
       "6  4 BHK For Sale  In Deccan Palms Park In Electr...  3,000 sqft   \n",
       "7  4 BHK In Independent House  For Sale  In Parap...  1,000 sqft   \n",
       "8  4 BHK In Independent House  For Sale  In Elect...  2,500 sqft   \n",
       "9  4 BHK In Independent House  For Sale  In Elect...  1,500 sqft   \n",
       "\n",
       "                                            location               EMI  \\\n",
       "0                                          6th Cross     ₹85,971/Month   \n",
       "1  Standalone Building, Shikaripalya near Shams S...     ₹20,060/Month   \n",
       "2  Sobha Silicon Oasis Naganathapura, Rayasandra ...     ₹85,971/Month   \n",
       "3  Independent House,  Shantipura Village , S.P L...     ₹40,120/Month   \n",
       "4  Independent House, Doddanagamangala Rd opposit...     ₹45,851/Month   \n",
       "5  Daadys GardenÂ  Kammasandra Rd, Kammasandra, E...     ₹85,971/Month   \n",
       "6  Deccan Palms ParkÂ  Deccan Palms Villas, Decca...     ₹85,971/Month   \n",
       "7  Independent House, Hosur Road CK Nagar near Sh...     ₹37,254/Month   \n",
       "8  Independent House,  Krishna reddy layout-Near ...  ₹1.43 Lacs/Month   \n",
       "9  Independent House, Industrial Area Near Tech M...     ₹57,314/Month   \n",
       "\n",
       "         price  \n",
       "0  ₹1.5 Crores  \n",
       "1     ₹35 Lacs  \n",
       "2  ₹1.5 Crores  \n",
       "3     ₹70 Lacs  \n",
       "4     ₹80 Lacs  \n",
       "5  ₹1.5 Crores  \n",
       "6  ₹1.5 Crores  \n",
       "7     ₹65 Lacs  \n",
       "8  ₹2.5 Crores  \n",
       "9     ₹1 Crore  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame\n",
    "house_details=pd.DataFrame({})\n",
    "house_details['House']=house_title\n",
    "house_details['Area']=Area\n",
    "house_details['location']=location\n",
    "house_details['EMI']=EMI\n",
    "house_details['price']=price\n",
    "house_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(house_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
